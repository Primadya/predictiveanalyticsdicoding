# -*- coding: utf-8 -*-
"""proyek.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xPitDHV7BxPpoJjO1nje-I1e1aV-aHqC

# Predictive Analytics : Kualitas pada Buah Pisang
- Nauval Dwi Primadya

## Deksripsi Proyek

### Deskripsi dan Latar Belakang dari Proyek Prediksi Kualitas pada Buah Pisang dengan menggunakan Machine Learning

Proyek ini berfokus pada pengembangan model machine learning untuk memprediksi kualitas buah pisang secara lebih akurat dan efisien. Saat ini, penilaian kualitas pisang masih dilakukan secara manual, yang membutuhkan banyak waktu, tenaga, dan memiliki potensi kesalahan tinggi. Kondisi ini menyebabkan kerugian bagi petani dan distributor, serta seringkali mengecewakan konsumen. Model prediksi kualitas pisang ini diharapkan dapat menjadi solusi yang lebih akurat, efisien, dan transparan dalam mengatasi permasalahan tersebut.

# 1.  Melakukan Import Library yang digunakan
"""

# Mengimpor pustaka untuk memuat data dan visualisasi
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Mengimpor fungsi untuk membagi data, skala, dan evaluasi model
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score  # metrik akurasi

# Mengimpor model-model klasifikasi
from sklearn.neighbors import KNeighborsClassifier  # KNN
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier  # RF, GB, Extra Trees
from sklearn.svm import SVC  # SVM
from sklearn.naive_bayes import BernoulliNB  # Naive Bayes
from sklearn.linear_model import LogisticRegression  # Logistic Regression

"""# 2. Data Understanding

merupakan tahapan untuk memahami informasi dari sebuah dataset dan digunakan untuk menentukan kualitas dari dataset tersebut. serta mendapatkan wawasan langkah apa saja yang akan diterapkan pada dataset tersebut.

## 2.1 Data Loading
Tahap *Data Loading* bertujuan untuk memuat dataset yang akan digunakan, sehingga mempermudah pemahaman terhadap data tersebut. Dataset ini telah melalui proses *pembersihan* dan *normalisasi* oleh penyusunnya, sehingga siap digunakan dan lebih mudah diakses, bahkan oleh pemula.

<br>

**Detail Dataset**

- **Title**: Kualitas Banana
- **Source**: [Kaggle](https://www.kaggle.com/datasets/l3llff/banana)
- **Visibility**: Public

## 2.2 Exploratory Data Analysis **(EDA)**

*Exploratory Data Analysis* adalah proses awal dalam menyelidiki data untuk memahami karakteristiknya, mengidentifikasi pola dan anomali, serta memverifikasi asumsi yang mungkin ada pada data tersebut. Metode ini umumnya memanfaatkan teknik statistik serta visualisasi grafis untuk menyajikan informasi dengan lebih jelas.

### Deskripsi Variabel
"""

df = pd.read_csv("dataset/banana_quality.csv")

df.head()

"""Informasi dari dataframe diatas adalah sebagai berikut, yang terdiri dari 8 kolom.

- **Size**: ukuran buah
- **Weight**: berat buah
- **Sweetness**: tingkat kemanisan buah
- **Softness**: kelembutan buah
- **HarvestTime**: waktu yang telah berlalu sejak buah dipanen
- **Ripeness**: tingkat kematangan buah
- **Acidity**: tingkat keasaman buah
- **Quality**: kualitas buah

"""

df.info()

"""Dari hasil eksekusi diperoleh informasi sebagai berikut:

- Ada 7 kolom dengan tipe data numerik float64, yaitu: Size, Weight, Sweetness, Softness, HarvestTime, Ripeness, dan Acidity.
- Terdapat 1 kolom bertipe data object, yaitu: Quality.
"""

df = df.rename(columns={'Quality': 'label'})

"""merubah Quality menjadi Label agar memudahkan dalam memproses"""

import matplotlib.pyplot as plt
import seaborn as sns

# Misalnya, kolom label bernama 'label'
label_counts = df['label'].value_counts()
# Menampilkan hasil
print(label_counts)

# Membuat plot batang
plt.figure(figsize=(10,6))
sns.barplot(x=label_counts.index, y=label_counts.values)
plt.title('Distribusi Label/Kategori')
plt.xlabel('Label/Kategori')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.show()

"""Menampilkan sebaran dataset dari masing-masing label. yaitu label `Good` dan `Bad`"""

df.describe()

"""memberikan infromasi statistik dari masing-masing kolom, antara lain sebagai berikut :
- `Count`: jumlah sampel dalam data
- `Mean`: rata-rata nilai
- `Std`: standar deviasi, yang menunjukkan sebaran data dari rata-rata
- `Min`: nilai minimum dalam setiap kolom
- `25%`: kuartil pertama, yaitu batas yang membagi data menjadi 25% bagian pertama
- `50%`: kuartil kedua atau median, yaitu nilai tengah data
- `75%`: kuartil ketiga, membagi data hingga 75% bagian
- `Max`: nilai maksimum dalam kolom

"""

df.shape

"""Memiliki Jumlah Baris `8000` dan kolom `8`"""

df['label'].value_counts()

"""Menghitung jumlah data dari masing-masing label.
<br>
didapatkan, pada label `Good : 4006` dan pada label `Bad : 3994`.
<br>
data dapat dikatakan `imbalance` namun masih masuk kategori normal. dikarenakan perbedaan jumlah data tidak terlalu signifikan.

### Menangani Missing Value dan Outlier
"""

df.duplicated().sum()

"""menghitung jumlah data yang duplikat."""

df.isnull().sum()

data_miss = df[df.isnull().any(axis=1)]
data_miss

"""Tidak terdapat daya yang `Missing Value` sehingga tidak perlu menghapus atau memperbaiki data.

### Menampilkan atau memvisualisasikan Outlier
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Pilih kolom numerik (kecuali object)
df_outlier = df.select_dtypes(exclude=['object'])

# Tentukan ukuran grid untuk subplot
num_columns = len(df_outlier.columns)
fig, axes = plt.subplots(nrows=1, ncols=num_columns, figsize=(num_columns*3, 5))

# Jika hanya ada satu kolom, axes bukan list
if num_columns == 1:
    axes = [axes]

# Membuat boxplot untuk setiap kolom dalam 1 frame
for i, column in enumerate(df_outlier.columns):
    sns.boxplot(data=df_outlier, x=column, ax=axes[i])
    axes[i].set_title(column)

# Menyesuaikan tata letak
plt.tight_layout()
plt.show()

"""*Menghilangkan outlier dalam dataset*

Pada kasus ini, kita akan menggunakan teknik visualisasi data (boxplot) untuk mendeteksi outlier. Setelah itu, outlier akan ditangani menggunakan metode IQR.

```
IQR = Inter Quartile Range
IQR = Q3 - Q1
```
"""

import pandas as pd

# Pastikan operasi hanya dilakukan pada kolom numerik
df_numeric = df.select_dtypes(include=[float, int])

# Menghitung Q1, Q3, dan IQR
Q1 = df_numeric.quantile(0.25)
Q3 = df_numeric.quantile(0.75)
IQR = Q3 - Q1

# Menghapus outlier berdasarkan IQR
df_numeric_clean = df_numeric[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]

# Menggabungkan kembali dengan kolom non-numerik (jika ada)
df = df.loc[df_numeric_clean.index]

# Menampilkan dataframe yang sudah bersih
print(df.head())

df.shape

"""Jumlah dataset setelah melakukan proses hapus outlier menjadi

### Univariate Analysis
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""### Multivariate Analysis"""

sns.pairplot(df, diag_kind = 'kde')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Memilih hanya kolom numerik untuk perhitungan korelasi
df_numeric = df.select_dtypes(include=[float, int])

# Membuat matriks korelasi
correlation_matrix = df_numeric.corr().round(2)

# Plot heatmap korelasi
plt.figure(figsize=(12, 10))
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Matriks Korelasi untuk Fitur Numerik", size=20)
plt.show()

"""## 3. Data Preparation

Merupakan tahapan untuk mempersiapkan data sebelum dilakukannya pemodelan machine learning

### Data Clening
"""

df['label'] = df['label'].map({'Good': 1, 'Bad': 0})

df.head()

"""Merubah nilai Label dari `Good` dan `Bad` menjadi `1 untuk Good` dan `0 untuk Bad`

### Train Test dan Split

data dipisahkan antara fitur dengan label.
<br>
selanjutnya dataset dibagi menjadi `80:20`
"""

# Pisahkan fitur dan label
X = df.drop('label', axis=1)  # Menghapus kolom label dari dataset
y = df['label']

X.shape,y.shape

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f'Total datasets: {len(X)}')
print(f'Total data Latih: {len(X_train)}')
print(f'Total data Uji: {len(X_test)}')

"""### Normalisasi"""

scaler = MinMaxScaler()
scaler.fit(X_train)
x_train = scaler.transform(X_train)
x_test = scaler.transform(X_test)

"""# 4. Pemodelan

Pada tahap pemodelan, menggunakan 5 model machine learning. yaitu sebagai berikut :
<br>
1. Random Forest
2. Gradient Boosting
3. SVM
4. KNN
5. Logistic Regression
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.model_selection import cross_val_score

# Daftar model yang akan dibandingkan
models = {
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'Support Vector Machine': SVC(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Logistic Regression': LogisticRegression(max_iter=1000)
}

# Menyimpan hasil akurasi untuk plotting
test_set_accuracies = []

# Membandingkan model-model dengan cross-validation
for name, model in models.items():
    # Cross-validation scores
    scores = cross_val_score(model, X_train, y_train, cv=5)

    # Fit model sekali pada seluruh X_train
    model.fit(X_train, y_train)

    # Prediksi pada set uji
    y_pred = model.predict(X_test)

    # Menghitung metrik
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    # Menyimpan akurasi untuk plotting
    test_set_accuracies.append((name, accuracy))  # Simpan nama model dan akurasi

    # Menampilkan hasil
    print(f'{name}:')
    print(f'  Cross-Validation Accuracy: {scores.mean():.4f}')
    print(f'  Test Set Accuracy: {accuracy:.4f}')
    print(f'  Precision: {precision:.4f}')
    print(f'  Recall: {recall:.4f}')
    print(f'  F1 Score: {f1:.4f}')
    print('  Confusion Matrix:')
    print(cm)
    print('--------------------------')

# Memastikan bahwa test_set_accuracies terisi
print("Hasil Akurasi Model:")
print(test_set_accuracies)

"""# 5. Evaluasi

didapatkan hasil akurasi terbaik pada SVM, selanjutnya pada KNN, dan Random Forest.
"""

import numpy as np
import matplotlib.pyplot as plt

# Mengambil nama model dan akurasi dari hasil evaluasi
model_names = [name for name, _ in test_set_accuracies]
test_set_accuracies_values = [accuracy for _, accuracy in test_set_accuracies]

# Memastikan bahwa nama model dan akurasi terisi
print("Nama Model:", model_names)
print("Akurasi Set Uji:", test_set_accuracies_values)

# Membuat plot sederhana
plt.figure(figsize=(12, 6))  # Ukuran figure
x = np.arange(len(model_names))  # label untuk sumbu x

# Membuat batang untuk akurasi
bars = plt.bar(x, test_set_accuracies_values, color='salmon')

# Menambahkan label dan judul dengan ukuran font yang lebih besar
plt.ylabel('Accuracy', fontsize=14)
plt.title('Test Set Accuracy of Models', fontsize=16)
plt.xticks(x, model_names, rotation=45, fontsize=12)
plt.ylim(0, 1)  # Mengatur batas sumbu Y

# Menambahkan label akurasi di dalam setiap batang
for i in range(len(model_names)):
    plt.text(i, test_set_accuracies_values[i] / 2, f'{test_set_accuracies_values[i]:.2f}',
             ha='center', color='black', fontsize=12)

# Menampilkan plot
plt.tight_layout()
plt.show()

